{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles Method\n",
    "\n",
    "In this topics, we will learn how to combine (or simply ensemble) the models we have tried in a way that makes combination of these models make better at predicting than the individual models.\n",
    "\n",
    "Commonly the \"weak\" learners we use are decision trees. In fact the default for most ensemble methods is a decision tree in sklearn. However, we can change this value to any of the models we have seen so far.\n",
    "\n",
    "## Why do we need to ensemble learner?\n",
    "\n",
    "There are two competing variables in finding a well fitting machine learning model: **Bias** and **Variance**.\n",
    "\n",
    "**Bias**: When a model has high bias, this means that means it doesn't do a good job of bending to the data. An example of an algorithm that usually has high bias is linear regression. Even with completely different datasets, we end up with the same line fit to the data. When models have high bias, this is bad.\n",
    "\n",
    "**Variance**: When a model has high variance, this means that it changes drastically to meet the needs of every point in our dataset. Linear models like the one above is low variance, but high bias. An example of an algorithm that tends to have a high variance and low bias is a decision tree (especially decision trees with no early stopping parameters). A decision tree, as a high variance algorithm, will attempt to split every point into it's own branch if possible. This is a trait of high variance, low bias algorithms - they are extremely flexible to fit exactly whatever data they see."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensembles Method in Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = pd.read_csv(\"../../data/spam.tsv\", sep='\\t', names=[\"label\", \"message\"])\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spam.shape)\n",
    "spam.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "spam_vector = vectorizer.fit_transform(spam[\"message\"])\n",
    "spam_features = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_vector.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(spam_vector.toarray(), columns=spam_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam['label'] = spam.label.map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spam_vector.toarray(), spam['label'], test_size=.2, random_state=111)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training accuracy: {accuracy_score(y_train, model.predict(X_train))}\")\n",
    "print(f\"test accuracy: {accuracy_score(y_test, model.predict(X_test))}\")\n",
    "\n",
    "print(f\"training recall: {recall_score(y_train, model.predict(X_train))}\")\n",
    "print(f\"test recall: {recall_score(y_test, model.predict(X_test))}\")\n",
    "\n",
    "print(f\"training precision: {precision_score(y_train, model.predict(X_train))}\")\n",
    "print(f\"test precision: {precision_score(y_test, model.predict(X_test))}\")\n",
    "\n",
    "print(f\"f1 score: {f1_score(y_train, model.predict(X_train))}\")\n",
    "print(f\"f1 score: {f1_score(y_test, model.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(criterion='entropy', random_state=1111)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_clf = BaggingClassifier(n_estimators=10, random_state=111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training accuracy: {accuracy_score(y_train, bagging_clf.predict(X_train))}\")\n",
    "print(f\"test accuracy: {accuracy_score(y_test, bagging_clf.predict(X_test))}\\n\")\n",
    "\n",
    "print(f\"training recall: {recall_score(y_train, bagging_clf.predict(X_train))}\")\n",
    "print(f\"test recall: {recall_score(y_test, bagging_clf.predict(X_test))}\\n\")\n",
    "\n",
    "print(f\"training precision: {precision_score(y_train, bagging_clf.predict(X_train))}\")\n",
    "print(f\"test precision: {precision_score(y_test, bagging_clf.predict(X_test))}\\n\")\n",
    "\n",
    "print(f\"f1 score: {f1_score(y_train, bagging_clf.predict(X_train))}\")\n",
    "print(f\"f1 score: {f1_score(y_test, bagging_clf.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(n_estimators=50, learning_rate=.5)\n",
    "t0 = time()\n",
    "ada_clf.fit(X_train, y_train)\n",
    "print(f\"finish training in {time()-t0:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"training accuracy: {accuracy_score(y_train, ada_clf.predict(X_train))}\")\n",
    "print(f\"test accuracy: {accuracy_score(y_test, ada_clf.predict(X_test))}\\n\")\n",
    "\n",
    "print(f\"training recall: {recall_score(y_train, ada_clf.predict(X_train))}\")\n",
    "print(f\"test recall: {recall_score(y_test, ada_clf.predict(X_test))}\\n\")\n",
    "\n",
    "print(f\"training precision: {precision_score(y_train, ada_clf.predict(X_train))}\")\n",
    "print(f\"test precision: {precision_score(y_test, ada_clf.predict(X_test))}\\n\")\n",
    "\n",
    "print(f\"f1 score: {f1_score(y_train, ada_clf.predict(X_train))}\")\n",
    "print(f\"f1 score: {f1_score(y_test, ada_clf.predict(X_test))}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
